{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sun Feb 10 4:44 am\n",
    "* Initial pass at an LSTM based on hydraseq\n",
    "* It has context, which builds a hirarchical tree of convos at high level\n",
    "* Still need to define state a little better with active/predicted\n",
    "* Still need to use context, add to it so we can handle she/it etc from one sentence to the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/niarfe/tmprepos/hydra_inc/hydraseq/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "! pwd\n",
    "import sys\n",
    "sys.path.append(\"/Users/niarfe/tmprepos/hydra_inc/hydraseq\")\n",
    "import hydraseq\n",
    "from hydraseq import Hydraseq\n",
    "from hydraseq.columns import run_convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"the quick brown fox jumped over the lazy dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, datasource=None):\n",
    "        self.hdq = hydraseq.Hydraseq('one')\n",
    "        self.sentence = \"\"\n",
    "        self.convos0 = []\n",
    "        self.convos1 = []\n",
    "        self.convos2 = []\n",
    "        if datasource: self.consume_data(datasource)\n",
    "        self.sdrs = [\n",
    "            self.sentence,\n",
    "            self.convos0,\n",
    "            self.convos1,\n",
    "            self.convos2\n",
    "        ]\n",
    "        self.context = []\n",
    "        \n",
    "    \n",
    "    def consume_data(self, fpath):\n",
    "        with open(fpath, 'r') as source:\n",
    "            [self.hdq.insert(line.strip()) for line in source]\n",
    "            \n",
    "    def process_sentence(self, sentence):\n",
    "        self.sdrs = []\n",
    "        self.sdrs.append(sentence.split())\n",
    "\n",
    "        self.convos0 = run_convolutions(sentence.split(), self.hdq, \"_\")\n",
    "        self.sdrs.append(self.convos0)\n",
    "        encoded = list(map(lambda x: x[2], self.convos0))\n",
    "\n",
    "        self.convos1 = run_convolutions(list(encoded), self.hdq, \"*\")\n",
    "        self.sdrs.append(self.convos1)\n",
    "        encoded = list(map(lambda x: x[2], self.convos1))\n",
    "            \n",
    "        self.convos2 = run_convolutions(encoded, self.hdq, \"#\")\n",
    "        self.sdrs.append(self.convos2)\n",
    "        \n",
    "        for convo in self.convos2:\n",
    "            tree = {}\n",
    "            self.treeify(tree, 3, convo)\n",
    "            self.context.append(tree)\n",
    "        return self\n",
    "\n",
    "    def treeify(self, tree, level, convo):\n",
    "        if level == 0:\n",
    "            #print(\"returning with \", convo)\n",
    "            tree['word'] = convo\n",
    "            return convo\n",
    "        #print(\"calling self.sdrs[{}][{}:{}]\".format(level-1, convo[0], convo[1]))\n",
    "        next_convos = self.sdrs[level-1][convo[0]:convo[1]]\n",
    "        current_dict = {}\n",
    "        tree[convo[2][0]] = current_dict\n",
    "        for conv in next_convos:\n",
    "            self.treeify(current_dict, level-1, conv)\n",
    "        \n",
    "    def __str__(self):\n",
    "        for sdr in self.sdrs:\n",
    "            print(sdr)\n",
    "            print()\n",
    "        print(self.context)\n",
    "        return \"OK\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n",
      "\n",
      "[[0, 1, ['_ART']], [1, 2, ['_ADJ']], [2, 3, ['_ADJ']], [3, 4, ['_NOU']], [4, 5, ['_VER']], [5, 6, ['_PRO']], [6, 7, ['_ART']], [7, 8, ['_ADJ']], [8, 9, ['_NOU']]]\n",
      "\n",
      "[[0, 4, ['*NP*']], [2, 4, ['*NP*']], [3, 4, ['*NP*']], [4, 5, ['*VP*']], [7, 9, ['*NP*']], [8, 9, ['*NP*']]]\n",
      "\n",
      "[[2, 4, ['#BINGO#']]]\n",
      "\n",
      "[{'#BINGO#': {'*NP*': {'_NOU': {'word': 'fox'}}, '*VP*': {'_VER': {'word': 'jumped'}}}}]\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(datasource='playdata.txt')\n",
    "\n",
    "lstm.process_sentence(sentence)\n",
    "\n",
    "print(lstm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
