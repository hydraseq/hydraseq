{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install hydraseq\n",
    "import hydraseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . . . . . . . . . n . . . X X X . . . n . . X . . . X . . n . X . . . . . X . n . X . . . . . X . n . X . . . . . X . n . . X . . . . X . n . . . X X X X . . n . . . . . . . . . n . . . . . . . . . n   \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "circle = \"\"\"\n",
    ".........n\n",
    "...XXX...n\n",
    "..X...X..n\n",
    ".X.....X.n\n",
    ".X.....X.n\n",
    ".X.....X.n\n",
    "..X....X.n\n",
    "...XXXX..n\n",
    ".........n\n",
    ".........n \n",
    "\"\"\".replace('\\n', '')\n",
    "\n",
    "square = \"\"\"\n",
    ".........n\n",
    ".XXXXXXX.n\n",
    ".X.....X.n\n",
    ".X.....X.n\n",
    ".X.....X.n\n",
    ".X.....X.n\n",
    ".X.....X.n\n",
    ".XXXXXXX.n\n",
    ".........n\n",
    ".........n \n",
    "\"\"\".replace('\\n', '')\n",
    "\n",
    "sletter = \"\"\"\n",
    ".........n\n",
    ".XXXXXXX.n\n",
    ".X.......n\n",
    ".X.......n\n",
    ".XXXXXXX.n\n",
    ".......X.n\n",
    ".......X.n\n",
    ".XXXXXXX.n\n",
    ".........n\n",
    ".........n \n",
    "\"\"\".replace('\\n', '')\n",
    "\n",
    "stream = re.sub(r'', ' ',circle)\n",
    "print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START CONVO   . . . . . . . . . n . . . X X X . . . n . . X . . . X . . n . X . . . . . X . n . X . . . . . X . n . X . . . . . X . n . . X . . . . X . n . . . X X X X . . n . . . . . . . . . n . . . . . . . . . n      _\n",
      "WORD= ['n'] depth= 8 idx= 10  ACTIVE SEQ:  [['.', 'n']]  next_word= _e\n",
      "WORD= ['.'] depth= 9 idx= 11  ACTIVE SEQ:  [['n', '.']]  next_word= _s\n",
      "WORD= ['X'] depth= 12 idx= 14  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 15 idx= 17  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['n'] depth= 18 idx= 20  ACTIVE SEQ:  [['.', 'n']]  next_word= _e\n",
      "WORD= ['.'] depth= 19 idx= 21  ACTIVE SEQ:  [['n', '.']]  next_word= _s\n",
      "WORD= ['X'] depth= 21 idx= 23  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 22 idx= 24  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['X'] depth= 25 idx= 27  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 26 idx= 28  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['n'] depth= 28 idx= 30  ACTIVE SEQ:  [['.', 'n']]  next_word= _e\n",
      "WORD= ['.'] depth= 29 idx= 31  ACTIVE SEQ:  [['n', '.']]  next_word= _s\n",
      "WORD= ['X'] depth= 30 idx= 32  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 31 idx= 33  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['X'] depth= 36 idx= 38  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 37 idx= 39  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['n'] depth= 38 idx= 40  ACTIVE SEQ:  [['.', 'n']]  next_word= _e\n",
      "WORD= ['.'] depth= 39 idx= 41  ACTIVE SEQ:  [['n', '.']]  next_word= _s\n",
      "WORD= ['X'] depth= 40 idx= 42  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 41 idx= 43  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['X'] depth= 46 idx= 48  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 47 idx= 49  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['n'] depth= 48 idx= 50  ACTIVE SEQ:  [['.', 'n']]  next_word= _e\n",
      "WORD= ['.'] depth= 49 idx= 51  ACTIVE SEQ:  [['n', '.']]  next_word= _s\n",
      "WORD= ['X'] depth= 50 idx= 52  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 51 idx= 53  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['X'] depth= 56 idx= 58  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 57 idx= 59  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['n'] depth= 58 idx= 60  ACTIVE SEQ:  [['.', 'n']]  next_word= _e\n",
      "WORD= ['.'] depth= 59 idx= 61  ACTIVE SEQ:  [['n', '.']]  next_word= _s\n",
      "WORD= ['X'] depth= 61 idx= 63  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 62 idx= 64  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['X'] depth= 66 idx= 68  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 67 idx= 69  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['n'] depth= 68 idx= 70  ACTIVE SEQ:  [['.', 'n']]  next_word= _e\n",
      "WORD= ['.'] depth= 69 idx= 71  ACTIVE SEQ:  [['n', '.']]  next_word= _s\n",
      "WORD= ['X'] depth= 72 idx= 74  ACTIVE SEQ:  [['.', 'X']]  next_word= _U\n",
      "WORD= ['.'] depth= 76 idx= 78  ACTIVE SEQ:  [['X', '.']]  next_word= _D\n",
      "WORD= ['n'] depth= 78 idx= 80  ACTIVE SEQ:  [['.', 'n']]  next_word= _e\n",
      "WORD= ['.'] depth= 79 idx= 81  ACTIVE SEQ:  [['n', '.']]  next_word= _s\n",
      "WORD= ['n'] depth= 88 idx= 90  ACTIVE SEQ:  [['.', 'n']]  next_word= _e\n",
      "WORD= ['.'] depth= 89 idx= 91  ACTIVE SEQ:  [['n', '.']]  next_word= _s\n",
      "WORD= ['n'] depth= 98 idx= 100  ACTIVE SEQ:  [['.', 'n']]  next_word= _e\n"
     ]
    }
   ],
   "source": [
    "hds0 = hydraseq.Hydraseq(\"_\")\n",
    "for pattern in [\n",
    "    \"X . _D\",\n",
    "    \". X _U\",\n",
    "    \". n _e\",\n",
    "    \"n . _s\",\n",
    "]:\n",
    "    hds0.insert(pattern)\n",
    "\n",
    "\n",
    "bigrams = hds0.convolutions(stream);\n",
    "bigram_list = [\"-\"]*len(stream)\n",
    "for idx, bigram in enumerate(bigrams):\n",
    "    bigram_list[bigram[0]] = bigram[2][0]\n",
    "\n",
    "for idx, bigram in enumerate(bigram_list):\n",
    "    if bigram == \"-\":\n",
    "        continue\n",
    "    else:\n",
    "        if bigram == \"_U\":\n",
    "            bigram_list[idx] = \"/\"\n",
    "        elif bigram == \"_D\":\n",
    "            bigram_list[idx] = \"\\\\\"\n",
    "        else:\n",
    "            bigram_list[idx] = bigram.replace('_', '')\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------es\n",
      "--/--\\--es\n",
      "-/\\--/\\-es\n",
      "/\\----/\\es\n",
      "/\\----/\\es\n",
      "/\\----/\\es\n",
      "-/\\---/\\es\n",
      "--/---\\-es\n",
      "--------es\n",
      "--------e-\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,100,10):\n",
    "    print(\"\".join(bigram_list[idx:idx+10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams  [[8, 10, ['_e']], [9, 11, ['_s']], [12, 14, ['_U']], [15, 17, ['_D']], [18, 20, ['_e']], [19, 21, ['_s']], [21, 23, ['_U']], [22, 24, ['_D']], [25, 27, ['_U']], [26, 28, ['_D']], [28, 30, ['_e']], [29, 31, ['_s']], [30, 32, ['_U']], [31, 33, ['_D']], [36, 38, ['_U']], [37, 39, ['_D']], [38, 40, ['_e']], [39, 41, ['_s']], [40, 42, ['_U']], [41, 43, ['_D']], [46, 48, ['_U']], [47, 49, ['_D']], [48, 50, ['_e']], [49, 51, ['_s']], [50, 52, ['_U']], [51, 53, ['_D']], [56, 58, ['_U']], [57, 59, ['_D']], [58, 60, ['_e']], [59, 61, ['_s']], [61, 63, ['_U']], [62, 64, ['_D']], [66, 68, ['_U']], [67, 69, ['_D']], [68, 70, ['_e']], [69, 71, ['_s']], [72, 74, ['_U']], [76, 78, ['_D']], [78, 80, ['_e']], [79, 81, ['_s']], [88, 90, ['_e']], [89, 91, ['_s']], [98, 100, ['_e']]]\n",
      "filled  [[0, 0, ['_s']], [0, 8, ['_fill']], [8, 10, ['_e']], [9, 11, ['_s']], [11, 12, ['_fill']], [12, 14, ['_U']], [14, 15, ['_fill']], [15, 17, ['_D']], [17, 18, ['_fill']], [18, 20, ['_e']], [19, 21, ['_s']], [21, 23, ['_U']], [22, 24, ['_D']], [24, 25, ['_fill']], [25, 27, ['_U']], [26, 28, ['_D']], [28, 30, ['_e']], [29, 31, ['_s']], [30, 32, ['_U']], [31, 33, ['_D']], [33, 36, ['_fill']], [36, 38, ['_U']], [37, 39, ['_D']], [38, 40, ['_e']], [39, 41, ['_s']], [40, 42, ['_U']], [41, 43, ['_D']], [43, 46, ['_fill']], [46, 48, ['_U']], [47, 49, ['_D']], [48, 50, ['_e']], [49, 51, ['_s']], [50, 52, ['_U']], [51, 53, ['_D']], [53, 56, ['_fill']], [56, 58, ['_U']], [57, 59, ['_D']], [58, 60, ['_e']], [59, 61, ['_s']], [61, 63, ['_U']], [62, 64, ['_D']], [64, 66, ['_fill']], [66, 68, ['_U']], [67, 69, ['_D']], [68, 70, ['_e']], [69, 71, ['_s']], [71, 72, ['_fill']], [72, 74, ['_U']], [74, 76, ['_fill']], [76, 78, ['_D']], [78, 80, ['_e']], [79, 81, ['_s']], [81, 88, ['_fill']], [88, 90, ['_e']], [89, 91, ['_s']], [91, 98, ['_fill']], [98, 100, ['_e']]]\n"
     ]
    }
   ],
   "source": [
    "print(\"bigrams \", bigrams)\n",
    "\n",
    "filled = [[0,0,['_s']]]\n",
    "for bigram in bigrams:\n",
    "    if filled[-1][1] < bigram[0]:\n",
    "        filled.append([filled[-1][1], bigram[0], ['_fill']])\n",
    "        filled.append(bigram)\n",
    "    else:\n",
    "        filled.append(bigram)\n",
    "print(\"filled \", filled)\n",
    "# hds = hydraseq.Hydraseq(\"_\")\n",
    "# hds.insert(stream+\" _stop\")\n",
    "# hds1 = hydraseq.Hydraseq(\"1_\")\n",
    "# for pattern in [\n",
    "#     \"_1 _A 1_1A\",\n",
    "#     \"_2 _A 1_2A\",\n",
    "#     \"_3 _A 1_3A\",\n",
    "#     \"_4 _A 1_4A\",\n",
    "#     \"_5 _A 1_5A\",\n",
    "#     \"_6 _A 1_6A\",\n",
    "#     \"_1 _B 1_1B\",\n",
    "#     \"_2 _B 1_2B\",\n",
    "#     \"_3 _B 1_3B\",\n",
    "#     \"_4 _B 1_4B\",\n",
    "#     \"_5 _B 1_5B\",\n",
    "#     \"_6 _B 1_6B\",\n",
    "    \n",
    "# ]:\n",
    "#     hds1.insert(pattern)\n",
    "\n",
    "\n",
    "# thoughts = hydraseq.think([hds, hds0, hds1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_s _fill _e\n",
      "_s _fill _U _fill _D _fill _e\n",
      "_s _U _D _fill _U _D _e\n",
      "_s _U _D _fill _U _D _e\n",
      "_s _U _D _fill _U _D _e\n",
      "_s _U _D _fill _U _D _e\n",
      "_s _U _D _fill _U _D _e\n",
      "_s _fill _U _fill _D _e\n",
      "_s _fill _e\n",
      "_s _fill _e\n"
     ]
    }
   ],
   "source": [
    "# TODO: This filler setup needs to go into a special convolution function\n",
    "# in the main code.\n",
    "row = []\n",
    "for fill in filled:\n",
    "    if fill[2][0] != '_e':\n",
    "        row.append(fill[2][0])\n",
    "    else:\n",
    "        row.append(fill[2][0])\n",
    "        print(\" \".join(row))\n",
    "        row = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,100,10):\n",
    "    print(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
