{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydraseq as hds\n",
    "from hydraseq import run_convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict\n",
    "Convo = namedtuple('Convo', ['start', 'end', 'pattern', 'lasts', 'nexts'])\n",
    "endcap = Convo(-1,-1,['end'], [],[])\n",
    "def to_convo_node(lst_stuff):\n",
    "    return Convo(lst_stuff[0], lst_stuff[1], lst_stuff[2], [], [])\n",
    "\n",
    "def link(conv1, conv2):\n",
    "    conv1.nexts.append(conv2)\n",
    "    conv2.lasts.append(conv1)\n",
    "\n",
    "def stackem(lst_convos):\n",
    "    frame = defaultdict(list)\n",
    "    ends = []\n",
    "    for convo in lst_convos:\n",
    "        if frame[convo[0]]:\n",
    "            for cnode in frame[convo[0]]:\n",
    "                convo_node = to_convo_node(convo)\n",
    "                link(cnode, convo_node)\n",
    "                ends.append(convo_node)\n",
    "                if cnode in ends: ends.remove(cnode)\n",
    "                frame[convo_node.end].append(convo_node)\n",
    "        else:\n",
    "            convo_node = to_convo_node(convo)\n",
    "            ends.append(convo_node)\n",
    "            frame[convo_node.end].append(convo_node)\n",
    "    return ends\n",
    "\n",
    "def recon(end_nodes):\n",
    "    stack = []\n",
    "    for node in end_nodes:\n",
    "        sentence = []\n",
    "        sentence.append([node.start, node.end, node.pattern])\n",
    "        while node.lasts:\n",
    "            node = node.lasts[0]\n",
    "            sentence.append([node.start, node.end, node.pattern])\n",
    "        sentence.reverse()\n",
    "        stack.append(sentence)\n",
    "    return stack\n",
    "\n",
    "def pats_only(sentence):\n",
    "    return [sent[2] for sent in sentence]\n",
    "\n",
    "def get_init_sentence_from_hydra(hd0):\n",
    "    sentence = []\n",
    "    node = hd0.n_init.nexts[0]\n",
    "    idx = 0\n",
    "    while node.nexts:\n",
    "        sentence.append([idx, idx+1, [node.key]])\n",
    "        node = node.nexts[0]\n",
    "        idx+=1\n",
    "    return [sentence]\n",
    "\n",
    "\n",
    "def run_them_all(sentences, hd1):\n",
    "    next_sentences = []\n",
    "    for sent in sentences:\n",
    "        conv = run_convolutions(pats_only(sent), hd1)\n",
    "        for item in recon(stackem(conv)):\n",
    "            next_sentences.append(item)\n",
    "    return next_sentences\n",
    "\n",
    "def think(lst_hydras):\n",
    "    active_layers = []\n",
    "    for idx, hydra in enumerate(lst_hydras):\n",
    "        sentences = run_them_all(sentences, hydra) if idx != 0 else get_init_sentence_from_hydra(hydra)\n",
    "        active_layers.append(sentences)\n",
    "    return active_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid: 0_\n",
       "n_init: <node: (*),(*)>:\n",
       "active values: ['END']\n",
       "next values: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd0 = hds.Hydraseq(\"0_\")\n",
    "hd0.insert(\"spring leaves spring END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd1 = hds.Hydraseq(\"1_\")\n",
    "encodes = [\n",
    "    \"spring 1_Adj\",\n",
    "    \"spring 1_Verb\",\n",
    "    \"spring 1_Noun\",\n",
    "    \"leaves 1_Noun\",\n",
    "    \"leaves 1_Verb\"\n",
    "]\n",
    "for encode in encodes:\n",
    "    hd1.insert(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd2 = hds.Hydraseq('_')\n",
    "for pattern in [\n",
    "    \"1_Noun _NP_\",\n",
    "    \"1_Adj 1_Noun _NP_\",\n",
    "    \"1_Verb _VP_\",\n",
    "    \"1_Adj 1_Noun _NP_\",\n",
    "    \"1_Adj 1_Adj 1_Adj 1_Noun _NP_\",\n",
    "\n",
    "]:\n",
    "    hd2.insert(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1, ['spring']], [1, 2, ['leaves']], [2, 3, ['spring']]]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = get_init_sentence_from_hydra(hd0)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd1 = hds.Hydraseq('1_')\n",
    "for pattern in [\n",
    "    \"o 1_eye\",\n",
    "    \"L 1_nose\",\n",
    "    \"m 1_mouth\",\n",
    "    \"sdfg 1_keys\",\n",
    "]:\n",
    "    hd1.insert(pattern)\n",
    "\n",
    "hd2 = hds.Hydraseq('2_')\n",
    "for pattern in [\n",
    "    \"1_eye 1_eye 2_eyes\",\n",
    "    \"1_nose 2_nose\",\n",
    "    \"1_mouth 2_mouth\",\n",
    "    \"1_keys 1_keys 1_keys 2_row\"\n",
    "]:\n",
    "    hd2.insert(pattern)\n",
    "\n",
    "hd3 = hds.Hydraseq('3_')    \n",
    "for pattern in [\n",
    "    \"2_eyes 2_nose 2_mouth 3_face\",\n",
    "    \"2_row 3_homerow\"\n",
    "]:\n",
    "    hd3.insert(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[0, 1, ['x']],\n",
       "   [1, 2, ['x']],\n",
       "   [2, 3, ['o']],\n",
       "   [3, 4, ['o']],\n",
       "   [4, 5, ['L']],\n",
       "   [5, 6, ['m']],\n",
       "   [6, 7, ['end']],\n",
       "   [7, 8, ['sdfg']],\n",
       "   [8, 9, ['sdfg']],\n",
       "   [9, 10, ['sdfg']],\n",
       "   [10, 11, ['sdfg']]]],\n",
       " [[[2, 3, ['1_eye']],\n",
       "   [3, 4, ['1_eye']],\n",
       "   [4, 5, ['1_nose']],\n",
       "   [5, 6, ['1_mouth']]],\n",
       "  [[7, 8, ['1_keys']],\n",
       "   [8, 9, ['1_keys']],\n",
       "   [9, 10, ['1_keys']],\n",
       "   [10, 11, ['1_keys']]]],\n",
       " [[[0, 2, ['2_eyes']], [2, 3, ['2_nose']], [3, 4, ['2_mouth']]],\n",
       "  [[0, 3, ['2_row']]],\n",
       "  [[1, 4, ['2_row']]]],\n",
       " [[[0, 3, ['3_face']]], [[0, 1, ['3_homerow']]], [[0, 1, ['3_homerow']]]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd0 = hds.Hydraseq(\"_\")\n",
    "hd0.insert(\"x x o o L m end sdfg sdfg sdfg sdfg _period\")\n",
    "think([hd0, hd1, hd2, hd3])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
